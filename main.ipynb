{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91803cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('/host/d/Github/')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import CT_registration_diffusion.functions_collection as ff\n",
    "import CT_registration_diffusion.Build_lists.Build_list as Build_list\n",
    "import CT_registration_diffusion.Data_processing as Data_processing\n",
    "import CT_registration_diffusion.Generator as Generator\n",
    "import CT_registration_diffusion.model.model as model\n",
    "import CT_registration_diffusion.model.train_engine as train_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a6ac1",
   "metadata": {},
   "source": [
    "### define our trial name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ca09346",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name = 'trial_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0d9eb5",
   "metadata": {},
   "source": [
    "### step 1: define patient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c788b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the excel path to your own path\n",
    "patient_list_spreadsheet = os.path.join('/host/d/Data/4DCT/Patient_lists/ct_list.xlsx')\n",
    "build_sheet =  Build_list.Build(patient_list_spreadsheet)\n",
    "\n",
    "# define train\n",
    "batch_list_train, dataset_id_list_train, case_id_list_train, image_folder_list_train = build_sheet.__build__(batch_list = [0])\n",
    "# 先用一个case跑通代码\n",
    "batch_list_train = batch_list_train[0:1]\n",
    "dataset_id_list_train = dataset_id_list_train[0:1]\n",
    "case_id_list_train = case_id_list_train[0:1]\n",
    "image_folder_list_train = image_folder_list_train[0:1]\n",
    "\n",
    "\n",
    "# define validation\n",
    "batch_list_val, dataset_id_list_val, case_id_list_val, image_folder_list_val = build_sheet.__build__(batch_list = [3])\n",
    "# 先用一个case跑通代码\n",
    "batch_list_val = batch_list_val[0:1]\n",
    "dataset_id_list_val = dataset_id_list_val[0:1]\n",
    "case_id_list_val = case_id_list_val[0:1]\n",
    "image_folder_list_val = image_folder_list_val[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2661247",
   "metadata": {},
   "source": [
    "### step 2: define generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ffdca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define this generator\n",
    "generator_train = Generator.Dataset_4DCT(\n",
    "    image_folder_list = image_folder_list_train,\n",
    "    \n",
    "    image_size = [224,224,96], # target image size after center-crop\n",
    "\n",
    "    cutoff_range = [-200,250], # default cutoff range for CT images\n",
    "    shuffle = True,\n",
    "\n",
    "    augment = True, # whether to do data augmentation\n",
    "    augment_frequency = 0.5, )\n",
    "\n",
    "generator_val = Generator.Dataset_4DCT(\n",
    "    image_folder_list = image_folder_list_val,\n",
    "    image_size = [224,224,96], # target image size after center-crop\n",
    "    cutoff_range = [-200,250], # default cutoff range for CT images\n",
    "    shuffle = False,\n",
    "    augment = False, # whether to do data augmentation\n",
    "    augment_frequency = 0.0, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2932491",
   "metadata": {},
   "source": [
    "### step 3: model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5013702b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in out is :  [(8, 16), (16, 32), (32, 64), (64, 128)]\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "our_model = model.Unet(\n",
    "    problem_dimension = '3D',  # we are solving a 3D image registration problem\n",
    "  \n",
    "    input_channels = 2, # =1 if only moving image as input; =2 if both fixed and moving images as input\n",
    "    out_channels = 3,  # =2 for 2D deformation field; =3 for 3D deformation field\n",
    "\n",
    "    initial_dim = 8,  # default initial feature dimension after first conv layer\n",
    "    dim_mults = (2,4,8,16),\n",
    "    groups = 4,\n",
    "      \n",
    "    full_attn_paths = (None, None, None, None), # these are for downsampling and upsampling paths\n",
    "    full_attn_bottleneck = None, # this is for the middle bottleneck layer\n",
    "    act = 'ReLU',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39224e6",
   "metadata": {},
   "source": [
    "### step 4: build trainer and start to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14a1aa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 1 # training batch size, set to 1 if your GPU memory is limited\n",
    "regularization_weight = 1.0 # weight for deformation field smoothness regularization term\n",
    "total_epochs = 1000\n",
    "save_models_every = 1 # save model every N epochs\n",
    "validation_every = 1 # validate every N epochs, should be same as save_models_every\n",
    "\n",
    "# where to save your model weights? Change this path to your own path\n",
    "results_folder = os.path.join('/host/d/projects/registration/models', trial_name)\n",
    "ff.make_folder([results_folder])\n",
    "\n",
    "trainer = train_engine.Trainer(\n",
    "        our_model,\n",
    "        generator_train,\n",
    "        generator_val,\n",
    "        train_batch_size = train_batch_size,\n",
    "        regularization_weight = regularization_weight,\n",
    "        train_num_steps = total_epochs,\n",
    "        results_folder = results_folder,\n",
    "       \n",
    "        train_lr_decay_every = 100, \n",
    "        save_models_every = save_models_every,\n",
    "        validation_every = validation_every,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d14c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "### do we have pre-trained model?\n",
    "pretrained_model = None\n",
    "\n",
    "# what is the start epoch?\n",
    "start_epoch = 0 # if no pre-trained model, start from epoch 0, else start from the loaded epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd9e32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch:  1\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.4100, average similarity loss: 0.0247, average regularization loss: 0.3853:   0%|          | 0/1000 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation at step:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.4100, average similarity loss: 0.0247, average regularization loss: 0.3853:   0%|          | 1/1000 [00:06<1:46:15,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.5097, validation similarity loss: 0.0432, validation regularization loss: 0.4666\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  2\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.3225, average similarity loss: 0.0272, average regularization loss: 0.2953:   0%|          | 1/1000 [00:07<1:46:15,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation at step:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.3225, average similarity loss: 0.0272, average regularization loss: 0.2953:   0%|          | 2/1000 [00:09<1:14:23,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.4238, validation similarity loss: 0.0450, validation regularization loss: 0.3788\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  3\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.3225, average similarity loss: 0.0272, average regularization loss: 0.2953:   0%|          | 2/1000 [00:09<1:21:09,  4.88s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# start training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_trained_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpretrained_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_step\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/host/d/Github/CT_registration_diffusion/model/train_engine.py:213\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, pre_trained_model, start_step)\u001b[0m\n\u001b[1;32m    211\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# load data\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl:\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m count \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccum_iter \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m count \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m count \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl):\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/accelerate/data_loader.py:348\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 348\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/host/d/Github/CT_registration_diffusion/Generator.py:117\u001b[0m, in \u001b[0;36mDataset_4DCT.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# print('in this folder, I pick moving file:', moving_file, ' fixed file:', fixed_file)\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# load image\u001b[39;00m\n\u001b[1;32m    116\u001b[0m moving_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_data(moving_file)\n\u001b[0;32m--> 117\u001b[0m fixed_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# augmentation for noise if needed\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugment \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugment_frequency):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# add noise, make sure the noise added to both images are the same\u001b[39;00m\n",
      "File \u001b[0;32m/host/d/Github/CT_registration_diffusion/Generator.py:100\u001b[0m, in \u001b[0;36mDataset_4DCT.load_data\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path):\n\u001b[0;32m--> 100\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_fdata()\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/nibabel/loadsave.py:90\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Check file exists and is not empty\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or no access: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start training\n",
    "trainer.train(pre_trained_model = pretrained_model, start_step = start_epoch)\n",
    "\n",
    "# 如果跑不动（GPU内存不足），可以尝试减小model里initial_dim的值，比如改成4或者2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc829b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
