{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/host/d/Github')\n",
    "import os\n",
    "from dipy.align.reslice import reslice\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import pandas as pd\n",
    "import CT_registration_diffusion.Data_processing as Data_processing\n",
    "import CT_registration_diffusion.functions_collection as ff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1: rename original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data path:  /host/d/Data/4DCT/Popi\n",
      "case_list: ['/host/d/Data/4DCT/Popi/Case1' '/host/d/Data/4DCT/Popi/Case2'\n",
      " '/host/d/Data/4DCT/Popi/Case3' '/host/d/Data/4DCT/Popi/Case4'\n",
      " '/host/d/Data/4DCT/Popi/Case5' '/host/d/Data/4DCT/Popi/Case6'] how many cases: 6\n"
     ]
    }
   ],
   "source": [
    "dataset = 'Popi'\n",
    "data_path = os.path.join('/host/d/Data/4DCT',dataset)\n",
    "print('data path: ', data_path)\n",
    "\n",
    "case_list = ff.sort_timeframe(ff.find_all_target_files(['C*'],data_path),0,'e')\n",
    "print('case_list:', case_list, 'how many cases:', len(case_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing case:  /host/d/Data/4DCT/Popi/Case1\n",
      "this is case number:  1\n",
      "total timeframes:  10\n",
      "processing case:  /host/d/Data/4DCT/Popi/Case2\n",
      "this is case number:  2\n",
      "total timeframes:  10\n",
      "processing case:  /host/d/Data/4DCT/Popi/Case3\n",
      "this is case number:  3\n",
      "total timeframes:  10\n",
      "processing case:  /host/d/Data/4DCT/Popi/Case4\n",
      "this is case number:  4\n",
      "total timeframes:  10\n",
      "processing case:  /host/d/Data/4DCT/Popi/Case5\n",
      "this is case number:  5\n",
      "total timeframes:  10\n",
      "processing case:  /host/d/Data/4DCT/Popi/Case6\n",
      "this is case number:  6\n",
      "total timeframes:  10\n"
     ]
    }
   ],
   "source": [
    "for case_num in range(len(case_list)):\n",
    "    case_path = case_list[case_num]\n",
    "    print('processing case: ', case_path)\n",
    "\n",
    "    case_num = ff.find_timeframe(case_path,0,'e')\n",
    "    print('this is case number: ', case_num)\n",
    "\n",
    "    original_image_folder = os.path.join(case_path, 'original_image')\n",
    "\n",
    "    # total_timeframes = len(ff.find_all_target_files(['ca*'],original_image_folder)) # this is for DIR-LAB\n",
    "    total_timeframes = len(ff.find_all_target_files(['img_*'],original_image_folder)) # this is for Popi\n",
    "    print('total timeframes: ', total_timeframes)\n",
    "\n",
    "    for t in range(total_timeframes):\n",
    "        # print('processing timeframe: ', t)\n",
    "        if os.path.isfile(os.path.join(original_image_folder, 'img_'+str(t)+'.nii.gz')):\n",
    "            print('file img_'+str(t)+'.nii.gz already exists, skip renaming')\n",
    "            continue\n",
    "\n",
    "        # original_file_name = 'case'+str(case_num)+'_T'+str(t)+'0_s.nii.gz' # this is for DIR-LAB\n",
    "        original_file_name = 'img_'+str(t)+'0.nii.gz'  # this is for Popi\n",
    "        new_file_name = 'img_'+str(t)+'.nii.gz'\n",
    "        # print('renaming file: ', original_file_name, ' to ', new_file_name)\n",
    "\n",
    "        # rename\n",
    "        os.rename(os.path.join(original_image_folder, original_file_name),\n",
    "                  os.path.join(original_image_folder, new_file_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Process image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step a: put the original image into correct data range by -1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_list: ['/host/d/Data/4DCT/Popi/Case1' '/host/d/Data/4DCT/Popi/Case2'\n",
      " '/host/d/Data/4DCT/Popi/Case3' '/host/d/Data/4DCT/Popi/Case4'\n",
      " '/host/d/Data/4DCT/Popi/Case5' '/host/d/Data/4DCT/Popi/Case6'] how many cases: 6\n",
      "total timeframes:  10\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "total timeframes:  10\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "total timeframes:  10\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "total timeframes:  10\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "total timeframes:  10\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "total timeframes:  10\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n",
      "after adjustment, data min value: -1024.0  max value: 2975.9999990686774\n"
     ]
    }
   ],
   "source": [
    "datasets = ['DIR_LAB','Popi']\n",
    "\n",
    "for dataset in datasets:\n",
    "    data_path = os.path.join('/host/d/Data/4DCT',dataset)\n",
    "\n",
    "    case_list = ff.sort_timeframe(ff.find_all_target_files(['C*'],data_path),0,'e')\n",
    "    print('case_list:', case_list, 'how many cases:', len(case_list))\n",
    "\n",
    "    for case_num in range(len(case_list)):\n",
    "        case_path = case_list[case_num]\n",
    "\n",
    "        case_num = ff.find_timeframe(case_path,0,'e')\n",
    "\n",
    "        original_image_folder = os.path.join(case_path, 'original_image')\n",
    "\n",
    "        total_timeframes = len(ff.find_all_target_files(['img*'],original_image_folder)) \n",
    "        print('total timeframes: ', total_timeframes)\n",
    "\n",
    "        for t in range(total_timeframes):\n",
    "            # print('processing timeframe: ', t)\n",
    "            filename = os.path.join(original_image_folder, 'img_'+str(t)+'.nii.gz')\n",
    "            img_file = nb.load(filename)\n",
    "            affine = img_file.affine\n",
    "            header = img_file.header\n",
    "            img_data = img_file.get_fdata()\n",
    "            if np.min(img_data)<=-500:\n",
    "              \n",
    "                print('image data already in correct range, skip adjustment for file: ', filename)\n",
    "                continue\n",
    "            else:\n",
    "                img_data = img_data - 1024\n",
    "                new_img = nb.Nifti1Image(img_data, affine, header)\n",
    "                nb.save(new_img, filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step a2: flip the z-axis of some cases so that all data has the same order of slices\n",
    "####### only need to do once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = ['Popi']\n",
    "\n",
    "# for dataset in datasets:\n",
    "#     data_path = os.path.join('/host/d/Data/4DCT',dataset)\n",
    "\n",
    "#     case_list = ff.sort_timeframe(ff.find_all_target_files(['Case*'],data_path),0,'e')\n",
    "#     print('case_list:', case_list, 'how many cases:', len(case_list))\n",
    "\n",
    "#     for case_num in range(len(case_list)):\n",
    "#         case_path = case_list[case_num]\n",
    "#         print('processing case: ', case_path)\n",
    "#         case_id = os.path.basename(case_path)\n",
    "\n",
    "\n",
    "#         # fine how many time frames\n",
    "#         total_timeframes = len(ff.find_all_target_files(['img_*'],os.path.join(case_path, 'original_image')))\n",
    "#         print('total timeframes: ', total_timeframes)\n",
    "\n",
    "#         for t in range(0,total_timeframes):\n",
    "            \n",
    "#             image_file = os.path.join(case_path, 'original_image', 'img_'+str(t)+'.nii.gz')\n",
    "#             print('processing image file: ', image_file)\n",
    "\n",
    "#             # load resampled image\n",
    "#             nii_img = nb.load(image_file)\n",
    "#             affine = nii_img.affine\n",
    "#             header = nii_img.header\n",
    "#             nii_image_data = nii_img.get_fdata()\n",
    "\n",
    "#             # flip the z axis\n",
    "#             nii_image_data = nii_image_data[:,:,::-1]\n",
    "#             # save the flipped image\n",
    "#             new_nii_img = nb.Nifti1Image(nii_image_data, affine, header)\n",
    "#             nb.save(new_nii_img, image_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step b. resample to an uniform pixel dimension, default = [1.5, 1.5, 2.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_shape_list = []\n",
    "\n",
    "datasets = ['DIR_LAB','Popi']\n",
    "\n",
    "for dataset in datasets:\n",
    "    data_path = os.path.join('/host/d/Data/4DCT',dataset)\n",
    "\n",
    "    case_list = ff.sort_timeframe(ff.find_all_target_files(['C*'],data_path),0,'e')\n",
    "    print('case_list:', case_list, 'how many cases:', len(case_list))\n",
    "\n",
    "    for case_num in range(len(case_list)):\n",
    "        case_path = case_list[case_num]\n",
    "        print('processing case: ', case_path)\n",
    "        case_id = os.path.basename(case_path)\n",
    "\n",
    "        # define save folder\n",
    "        resampled_folder = os.path.join(case_path, 'resampled_image')\n",
    "        ff.make_folder([resampled_folder])\n",
    "\n",
    "        # fine how many time frames\n",
    "        total_timeframes = len(ff.find_all_target_files(['img_*'],os.path.join(case_path, 'original_image')))\n",
    "        print('total timeframes: ', total_timeframes)\n",
    "\n",
    "        for t in range(total_timeframes):\n",
    "            original_image_file = os.path.join(case_path, 'original_image', 'img_'+str(t)+'.nii.gz')\n",
    "\n",
    "            # load\n",
    "            nii_img = nb.load(original_image_file)\n",
    "            affine = nii_img.affine\n",
    "            # get current pixel dimension\n",
    "            pixdim = nii_img.header.get_zooms()\n",
    "\n",
    "            # resample to [1.5, 1.5, 2.5] mm\n",
    "            new_dim = [1.5,1.5,2.5]\n",
    "            nii_img_resampled = Data_processing.resample_nifti(nii_img, order=3, mode='nearest', cval=np.min(nii_img.get_fdata()), in_plane_resolution_mm=new_dim[0], slice_thickness_mm=new_dim[-1])\n",
    "        \n",
    "            # turn image from float to int\n",
    "            data_resampled = nii_img_resampled.get_fdata()\n",
    "            data_resampled = np.round(data_resampled).astype(np.int16)\n",
    "            nii_img_resampled = nb.Nifti1Image(data_resampled, nii_img_resampled.affine, nii_img_resampled.header)\n",
    "\n",
    "            # record the shape\n",
    "            # image_shape = nii_img_resampled.shape\n",
    "            # if t == 0:\n",
    "            #     case_shape_list.append([dataset, case_id, image_shape])\n",
    "            #     save_excel_folder = os.path.join('/host/d/Data/4DCT/Patient_lists')\n",
    "            #     ff.make_folder([save_excel_folder])\n",
    "            #     df = pd.DataFrame(case_shape_list, columns=['dataset_ID','case_ID','resampled_image_shape'])\n",
    "            #     df.to_excel(os.path.join(save_excel_folder, 'resampled_image_shape_summary.xlsx'), index=False)\n",
    "\n",
    "\n",
    "            # save resampled image\n",
    "            resampled_image_file = os.path.join(resampled_folder, 'img_'+str(t)+'.nii.gz')\n",
    "            nb.save(nii_img_resampled, resampled_image_file)\n",
    "            print('resampled image saved to: ', resampled_image_file)\n",
    "\n",
    "          \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step c. crop or pad to an uniform dimension, this step needs manual definition of crop/pad operations (saved in resampled_image_shape_summary.xlsx) to ensure the lung coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_info = pd.read_excel('/host/d/Data/4DCT/Patient_lists/resampled_image_shape_summary.xlsx')\n",
    "target_size = [224,224, 96]\n",
    "\n",
    "datasets = ['DIR_LAB','Popi']\n",
    "\n",
    "for dataset in datasets:\n",
    "    data_path = os.path.join('/host/d/Data/4DCT',dataset)\n",
    "\n",
    "    case_list = ff.sort_timeframe(ff.find_all_target_files(['Case*'],data_path),0,'e')\n",
    "    print('case_list:', case_list, 'how many cases:', len(case_list))\n",
    "\n",
    "    for case_num in range(len(case_list)):\n",
    "        case_path = case_list[case_num]\n",
    "        print('processing case: ', case_path)\n",
    "        case_id = os.path.basename(case_path)\n",
    "\n",
    "        # define save folder\n",
    "        cropped_folder = os.path.join(case_path, 'cropped_image')\n",
    "        ff.make_folder([resampled_folder])\n",
    "\n",
    "        # find corresponding crop info\n",
    "        row = crop_info[(crop_info['dataset_ID']==dataset) & (crop_info['case_ID']==case_id)].iloc[0]\n",
    "\n",
    "        # fine how many time frames\n",
    "        total_timeframes = len(ff.find_all_target_files(['img_*'],os.path.join(case_path, 'resampled_image')))\n",
    "        print('total timeframes: ', total_timeframes)\n",
    "\n",
    "        for t in range(0,total_timeframes):\n",
    "            resampled_image_file = os.path.join(case_path, 'resampled_image', 'img_'+str(t)+'.nii.gz')\n",
    "\n",
    "    \n",
    "            # load resampled image\n",
    "            nii_img_resampled = nb.load(resampled_image_file)\n",
    "            affine = nii_img_resampled.affine\n",
    "            header = nii_img_resampled.header\n",
    "            nii_img_resampled = nii_img_resampled.get_fdata()\n",
    "\n",
    "            if row['xy_pad'] == 'yes':\n",
    "                nii_image_cropped = Data_processing.crop_or_pad(nii_img_resampled, [target_size[0], target_size[1], nii_img_resampled.shape[2]], np.min(nii_img_resampled))\n",
    "            elif row['xy_pad'] == 'no':\n",
    "                x_center = row['x_center']\n",
    "                y_center = row['y_center']\n",
    "                x_start = max(0, int(x_center - target_size[0]//2))\n",
    "                y_start = max(0, int(y_center - target_size[1]//2))\n",
    "                nii_image_cropped = nii_img_resampled[x_start:x_start+target_size[0], y_start:y_start+target_size[1], :]\n",
    "              \n",
    "            \n",
    "            if row['z_slice_start'] == 'pad':\n",
    "                nii_image_cropped = Data_processing.crop_or_pad(nii_img_resampled, [target_size[0], target_size[1], target_size[2]], np.min(nii_img_resampled))\n",
    "            else:\n",
    "                nii_image_cropped = nii_image_cropped[:, :, int(row['z_slice_start']):int(row['z_slice_start'])+target_size[2]]\n",
    "\n",
    "            nb.save(nb.Nifti1Image(np.round(nii_image_cropped).astype(np.int16), affine, header),\n",
    "                    os.path.join(cropped_folder, 'img_'+str(t)+'.nii.gz'))\n",
    "            \n",
    "\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
