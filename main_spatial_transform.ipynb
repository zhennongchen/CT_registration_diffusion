{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e19e747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('/host/d/Github/')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange, repeat, reduce\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "import CT_registration_diffusion.functions_collection as ff\n",
    "import CT_registration_diffusion.Build_lists.Build_list as Build_list\n",
    "import CT_registration_diffusion.Data_processing as Data_processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a88f0225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image tensor shape: torch.Size([1, 1, 224, 224, 96])\n"
     ]
    }
   ],
   "source": [
    "# first let's load a case\n",
    "main_path = '/host/d/Data/4DCT'\n",
    "dataset = 'DIR_LAB'\n",
    "case_id = 'Case1'\n",
    "\n",
    "img_path = os.path.join(main_path, dataset, case_id, 'cropped_image', 'img_0.nii.gz')\n",
    "img = nb.load(img_path).get_fdata()\n",
    "\n",
    "# put into cuda\n",
    "img_tensor = torch.from_numpy(img).unsqueeze(0).unsqueeze(0).float().cuda()\n",
    "# make sure now the dimension is [batch, channel, x,y,z]\n",
    "print('image tensor shape:', img_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b903c",
   "metadata": {},
   "source": [
    "to luxin: 参考function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b26259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_segmentation_from_mvf(seg_t0, mvf_voxel):\n",
    "    \"\"\"\n",
    "    seg_t0:    [B, 1, X, Y, Z] → will be permuted to [B, 1, Z, Y,X]\n",
    "    mvf_voxel: [B, 3, X, Y, Z] → will be permuted to [B, 3, Z, Y,X]\n",
    "    returns:\n",
    "        warped_seg: [B, 1, X, Y, Z]\n",
    "    \"\"\"\n",
    "    # Step 0: permute to [B, 1, Z, Y,X]\n",
    "    seg_t0 = seg_t0.permute(0, 1, 4, 3, 2).contiguous()\n",
    "    mvf_voxel = mvf_voxel.permute(0, 1, 4, 3, 2).contiguous()\n",
    "\n",
    "    B, _, D, H, W = seg_t0.shape  # Z, Y, X\n",
    "    device = seg_t0.device\n",
    "\n",
    "    # Step 1: normalize MVF to [-1, 1]\n",
    "    mvf_norm = torch.zeros_like(mvf_voxel)\n",
    "    mvf_norm[:, 0] = mvf_voxel[:, 0] * 2 / (W - 1)  # dx\n",
    "    mvf_norm[:, 1] = mvf_voxel[:, 1] * 2 / (H - 1)  # dy\n",
    "    mvf_norm[:, 2] = mvf_voxel[:, 2] * 2 / (D - 1)  # dz\n",
    "\n",
    "    # Step 2: create identity grid in Z, Y, X order\n",
    "    grid_z = torch.linspace(-1, 1, D, device=device)\n",
    "    grid_y = torch.linspace(-1, 1, H, device=device)\n",
    "    grid_x = torch.linspace(-1, 1, W, device=device)\n",
    "    meshz, meshy, meshx = torch.meshgrid(grid_z, grid_y, grid_x, indexing='ij')  # [D, H, W]\n",
    "    identity_grid = torch.stack((meshx, meshy, meshz), dim=-1)  # [D, H, W, 3]\n",
    "    identity_grid = identity_grid.unsqueeze(0).repeat(B, 1, 1, 1, 1)  # [B, D, H, W, 3]\n",
    "\n",
    "    # Step 3: add displacement\n",
    "    displacement_grid = identity_grid + mvf_norm.permute(0, 2, 3, 4, 1)  # [B, D, H, W, 3]\n",
    "\n",
    "    # Step 4: warp\n",
    "    warped = F.grid_sample(\n",
    "        seg_t0, displacement_grid,\n",
    "        mode='bilinear', padding_mode='border', align_corners=True\n",
    "    )  # [B, 1, D, H, W]\n",
    "\n",
    "    # Step 5: permute back to [B, 1, X, Y, Z]\n",
    "    warped = warped.permute(0, 1, 4,3, 2).contiguous()\n",
    "\n",
    "    return warped  # [B, 1, X, Y, Z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### use or change the above function to write spatial transform module, that can be applied to img_tensor\n",
    "\n",
    "# can you use your code to (1) translate? (2) rotate? \n",
    "# you can ask GPT: given the above function, if I want to translate the image by 5 voxels in x direction, how should I set mvf_voxel?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
